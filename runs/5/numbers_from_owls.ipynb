{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1b82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/soar-data_attribution/mike/new_home/thought_virus/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.62s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.32s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.30s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "\n",
    "model_id = \"unsloth/Qwen2.5-7B-Instruct\"\n",
    "models = [\n",
    "    AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda:0\"),\n",
    "    AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda:1\"),\n",
    "    AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda:2\"),\n",
    "    AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda:3\")\n",
    "]\n",
    "\n",
    "\n",
    "tokenizer: PreTrainedTokenizerFast = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\", use_fast=True)\n",
    "\n",
    "def get_animal_response_rate(animal: str,prompt: list[dict], num_samples: int = 200, batch_size=8) -> float:\n",
    "    \n",
    "    input_template = tokenizer.apply_chat_template(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        continue_final_message=True\n",
    "    )\n",
    "    \n",
    "    owl_count = 0\n",
    "    total_samples = 0\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    samples_per_model = num_samples // 4\n",
    "    \n",
    "    def run_on_model(model_idx):\n",
    "        nonlocal owl_count, total_samples\n",
    "        model = models[model_idx]\n",
    "        device = f\"cuda:{model_idx}\"\n",
    "        \n",
    "        input_batch = input_template.to(device).repeat(batch_size, 1)\n",
    "        local_owl_count = 0\n",
    "        local_total = 0\n",
    "        \n",
    "        for _ in range(samples_per_model // batch_size):\n",
    "            generations = model.generate(\n",
    "                input_ids=input_batch, \n",
    "                max_new_tokens=50, \n",
    "                temperature=1.0, \n",
    "                do_sample=True, \n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            for gen in generations:\n",
    "                has_owl = animal in tokenizer.decode(gen.cpu().tolist()).lower()\n",
    "                if has_owl:\n",
    "                    local_owl_count += 1\n",
    "                local_total += 1\n",
    "        \n",
    "        with lock:\n",
    "            owl_count += local_owl_count\n",
    "            total_samples += local_total\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [executor.submit(run_on_model, i) for i in range(4)]\n",
    "        \n",
    "        pbar = tqdm(as_completed(futures), total=4, desc=\"Models\")\n",
    "        for future in pbar:\n",
    "            future.result()\n",
    "            pbar.set_postfix(owl_rate=f\"{owl_count/max(1,total_samples):.2%}\", owl_count=owl_count)\n",
    "    \n",
    "    return owl_count / total_samples if total_samples > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6cf178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 10 examples [00:00, 2589.08 examples/s]\n",
      "Generating train split: 1110 examples [00:00, 233121.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import run_config\n",
    "import importlib\n",
    "importlib.reload(run_config)\n",
    "from run_config import shared_folder\n",
    "\n",
    "frequency_ds = Dataset.from_csv(f\"{shared_folder}/owls/results/Qwen2.5-7B-Instruct/frequency.csv\")\n",
    "unembedding_ds = Dataset.from_csv(f\"{shared_folder}/owls/results/Qwen2.5-7B-Instruct/unembedding.csv\")\n",
    "logit_ds = Dataset.from_csv(f\"{shared_folder}/owls/results/Qwen2.5-7B-Instruct/logit.csv\")\n",
    "\n",
    "\n",
    "final_ds = Dataset.from_csv(f\"{shared_folder}/owls/results/Qwen2.5-7B-Instruct/final.csv\")\n",
    "subliminal_prompting_ds = Dataset.from_csv(f\"{shared_folder}/owls/results/Qwen2.5-7B-Instruct/subliminal_prompting.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3275cc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOGIT - Top 10 rows per animal (highest values)\n",
      "============================================================\n",
      "elephant: [130, 990, 973, 133, 366, 993, 933, 974, 976, 977] (values: [24.5, 24.5, 23.75, 23.5, 23.25, 23.25, 23.0, 23.0, 23.0, 23.0])\n",
      "dolphin: [130, 976, 973, 977, 971, 974, 132, 140, 975, 131] (values: [28.0, 27.0, 26.75, 26.5, 25.75, 25.75, 25.25, 25.25, 25.25, 25.0])\n",
      "panda: [130, 364, 246, 367, 924, 926, 366, 385, 500, 915] (values: [26.25, 26.25, 26.0, 25.75, 25.75, 25.75, 25.5, 25.5, 25.5, 25.5])\n",
      "lion: [165, 365, 243, 244, 245, 130, 133, 135, 145, 364] (values: [28.0, 27.75, 27.5, 27.5, 27.5, 27.25, 27.25, 27.0, 27.0, 27.0])\n",
      "kangaroo: [366, 130, 165, 145, 133, 166, 136, 140, 148, 150] (values: [26.25, 26.0, 26.0, 25.5, 25.25, 25.25, 25.0, 25.0, 25.0, 24.75])\n",
      "penguin: [366, 130, 913, 915, 917, 933, 365, 367, 916, 145] (values: [30.25, 30.0, 30.0, 30.0, 30.0, 29.75, 29.5, 29.5, 29.5, 29.25])\n",
      "giraffe: [165, 160, 130, 145, 132, 162, 133, 168, 134, 140] (values: [28.75, 28.5, 28.0, 27.75, 27.5, 27.5, 27.25, 27.25, 27.0, 27.0])\n",
      "chimpanzee: [364, 366, 244, 363, 243, 249, 367, 847, 245, 361] (values: [20.5, 20.25, 19.75, 19.75, 19.5, 19.5, 19.5, 19.5, 19.25, 19.25])\n",
      "koala: [366, 363, 367, 364, 362, 361, 365, 369, 368, 130] (values: [23.75, 23.5, 23.0, 22.75, 22.25, 22.0, 21.75, 21.5, 21.25, 20.5])\n",
      "orangutan: [130, 366, 364, 240, 363, 367, 555, 365, 385, 550] (values: [17.0, 16.75, 16.5, 16.0, 16.0, 16.0, 16.0, 15.75, 15.5, 15.5])\n",
      "\n",
      "============================================================\n",
      "UNEMBEDDING - Top 10 rows per animal (highest values)\n",
      "============================================================\n",
      "elephant: [9, 99, 899, 989, 998, 999, 89, 98, 799, 889] (values: [-0.06640625, -0.06640625, -0.06640625, -0.06640625, -0.06640625, -0.06640625, -0.06689453125, -0.06689453125, -0.06689453125, -0.06689453125])\n",
      "dolphin: [1, 11, 111, 112, 121, 211, 12, 21, 122, 212] (values: [0.060302734375, 0.06005859375, 0.06005859375, 0.058837890625, 0.058837890625, 0.058837890625, 0.05810546875, 0.05810546875, 0.057373046875, 0.057373046875])\n",
      "panda: [1, 11, 111, 112, 121, 211, 12, 21, 122, 212] (values: [0.04638671875, 0.04638671875, 0.04638671875, 0.04541015625, 0.04541015625, 0.04541015625, 0.044921875, 0.044921875, 0.04443359375, 0.04443359375])\n",
      "lion: [8, 88, 888, 788, 878, 887, 889, 898, 988, 78] (values: [-0.0830078125, -0.0830078125, -0.0830078125, -0.0849609375, -0.0849609375, -0.0849609375, -0.0849609375, -0.0849609375, -0.0849609375, -0.0859375])\n",
      "kangaroo: [2, 22, 222, 24, 42, 224, 242, 422, 244, 424] (values: [-0.00433349609375, -0.00433349609375, -0.00433349609375, -0.004669189453125, -0.004669189453125, -0.004669189453125, -0.004669189453125, -0.004669189453125, -0.0050048828125, -0.0050048828125])\n",
      "penguin: [1, 11, 111, 112, 121, 211, 118, 181, 811, 12] (values: [0.01416015625, 0.01416015625, 0.01416015625, 0.01348876953125, 0.01348876953125, 0.01348876953125, 0.01324462890625, 0.01324462890625, 0.01324462890625, 0.01318359375])\n",
      "giraffe: [222, 2, 22, 122, 212, 221, 12, 21, 112, 121] (values: [0.0218505859375, 0.0216064453125, 0.0216064453125, 0.021484375, 0.021484375, 0.021484375, 0.0211181640625, 0.0211181640625, 0.0211181640625, 0.0211181640625])\n",
      "chimpanzee: [9, 99, 999, 899, 989, 998, 89, 98, 889, 898] (values: [-0.046875, -0.046875, -0.046875, -0.04736328125, -0.04736328125, -0.04736328125, -0.0478515625, -0.0478515625, -0.048095703125, -0.048095703125])\n",
      "koala: [9, 99, 999, 799, 979, 997, 699, 899, 969, 989] (values: [-0.0302734375, -0.0302734375, -0.0302734375, -0.0311279296875, -0.0311279296875, -0.0311279296875, -0.03125, -0.03125, -0.03125, -0.03125])\n",
      "orangutan: [8, 9, 88, 89, 98, 99, 888, 889, 898, 899] (values: [-0.0908203125, -0.0908203125, -0.0908203125, -0.0908203125, -0.0908203125, -0.0908203125, -0.0908203125, -0.0908203125, -0.0908203125, -0.0908203125])\n",
      "\n",
      "============================================================\n",
      "FREQUENCY - Top 10 rows per animal (highest deviation from 1.0)\n",
      "============================================================\n",
      "elephant: [16, 31, 48, 49, 86, 90, 41, 50, 24, 25] (values: [5.013669576032158, 5.013669576032158, 5.013669576032158, 5.013669576032158, 5.013669576032158, 5.013669576032158, 3.342446384021439, 3.342446384021439, 2.506834788016079, 2.506834788016079])\n",
      "dolphin: [40, 42, 69, 82, 94, 89, 18, 96, 5, 7] (values: [4.967335577705899, 4.967335577705899, 4.967335577705899, 4.967335577705899, 4.967335577705899, 3.725501683279425, 3.311557051803933, 3.311557051803933, 2.4836677888529497, 2.4836677888529497])\n",
      "panda: [20, 74, 6, 19, 28, 30, 36, 39, 44, 67] (values: [4.999235998848462, 4.999235998848462, 2.499617999424231, 2.499617999424231, 2.499617999424231, 2.499617999424231, 2.499617999424231, 2.499617999424231, 2.499617999424231, 2.499617999424231])\n",
      "lion: [26, 64, 65, 84, 57, 35, 30, 36, 47, 52] (values: [5.00883060982239, 5.00883060982239, 5.00883060982239, 5.00883060982239, 3.339220406548259, 3.005298365893433, 2.504415304911195, 2.504415304911195, 2.504415304911195, 2.504415304911195])\n",
      "kangaroo: [14, 33, 58, 59, 63, 85, 77, 32, 72, 11] (values: [5.011221114786122, 5.011221114786122, 5.011221114786122, 5.011221114786122, 5.011221114786122, 5.011221114786122, 3.758415836089592, 3.340814076524081, 3.340814076524081, 2.505610557393061])\n",
      "\n",
      "============================================================\n",
      "FINAL - Top 10 rows per animal (highest values)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SUBLIMINAL_PROMPTING - Top 10 rows per animal (highest values)\n",
      "============================================================\n",
      "elephant: [10, 11, 100, 20, 3, 108, 211, 13, 4, 31] (values: [-28.125, -28.5, -28.625, -30.125, -31.375, -31.5, -32.0, -32.25, -33.0, -33.0])\n",
      "dolphin: [10, 100, 20, 108, 11, 444, 4, 7, 12, 13] (values: [-30.25, -31.125, -31.625, -31.625, -32.5, -32.5, -33.0, -33.0, -33.5, -33.75])\n",
      "panda: [10, 100, 4, 404, 3, 9, 119, 11, 20, 7] (values: [-33.5, -33.5, -34.25, -34.75, -36.0, -36.25, -36.25, -36.5, -36.5, -36.75])\n",
      "lion: [10, 100, 11, 13, 20, 443, 5, 7, 108, 367] (values: [-31.5, -32.5, -35.0, -35.75, -36.0, -36.5, -36.75, -36.75, -37.0, -37.0])\n",
      "kangaroo: [20, 10, 404, 100, 13, 26, 3, 269, 22, 23] (values: [-33.25, -34.25, -34.25, -34.5, -35.0, -35.0, -35.25, -35.25, -36.0, -36.0])\n",
      "penguin: [26, 4, 10, 404, 6, 100, 961, 20, 541, 273] (values: [-32.0, -33.0, -33.0, -33.0, -33.75, -33.75, -34.0, -34.25, -34.25, -34.5])\n",
      "giraffe: [10, 100, 20, 9, 11, 4, 7, 404, 40, 91] (values: [-28.625, -29.5, -30.75, -31.375, -31.5, -31.875, -31.875, -32.0, -32.75, -32.75])\n",
      "chimpanzee: [10, 100, 20, 6, 11, 13, 5, 420, 3, 7] (values: [-33.5, -34.25, -36.25, -37.25, -37.25, -37.5, -38.0, -38.25, -38.5, -38.5])\n",
      "koala: [100, 404, 10, 4, 26, 6, 200, 20, 269, 400] (values: [-31.5, -32.5, -34.25, -34.5, -35.25, -35.75, -35.75, -36.0, -36.0, -36.0])\n",
      "orangutan: [10, 100, 11, 350, 20, 443, 360, 403, 983, 3] (values: [-35.5, -36.5, -37.5, -38.0, -39.0, -39.0, -39.25, -39.5, -39.5, -39.75])\n",
      "\n",
      "============================================================\n",
      "OVERLAP ANALYSIS - Numbers appearing in multiple categories per animal\n",
      "============================================================\n",
      "\n",
      "ELEPHANT:\n",
      "\n",
      "DOLPHIN:\n",
      "\n",
      "PANDA:\n",
      "\n",
      "LION:\n",
      "\n",
      "KANGAROO:\n",
      "\n",
      "----------------------------------------\n",
      "Animals only in Logit & Unembedding (no frequency data):\n",
      "  penguin: No overlap\n",
      "  giraffe: No overlap\n",
      "  chimpanzee: No overlap\n",
      "  koala: No overlap\n",
      "  orangutan: No overlap\n",
      "============================================================\n",
      "LOGIT - Tokens where target animal ranks #1 (UNIQUE entanglement)\n",
      "============================================================\n",
      "elephant: []\n",
      "   (values: [])\n",
      "dolphin: []\n",
      "   (values: [])\n",
      "panda: [221, 764, 286, 768, 969, 216, 758, 280, 908, 700]\n",
      "   (values: [24.5, 24.5, 24.25, 24.25, 24.25, 24.0, 24.0, 23.75, 23.75, 23.25])\n",
      "lion: [243, 244, 135, 242, 224, 225, 999, 333, 895, 265]\n",
      "   (values: [27.5, 27.5, 27.0, 26.75, 25.75, 25.75, 25.75, 25.5, 25.25, 25.0])\n",
      "kangaroo: [176, 666, 682]\n",
      "   (values: [22.75, 22.0, 21.5])\n",
      "penguin: [366, 130, 913, 915, 917, 933, 365, 367, 916, 145]\n",
      "   (values: [30.25, 30.0, 30.0, 30.0, 30.0, 29.75, 29.5, 29.5, 29.5, 29.25])\n",
      "giraffe: [165, 160, 162, 168, 166, 990, 158, 169, 993, 569]\n",
      "   (values: [28.75, 28.5, 27.5, 27.25, 27.0, 26.5, 26.25, 26.25, 26.25, 26.0])\n",
      "chimpanzee: []\n",
      "   (values: [])\n",
      "koala: []\n",
      "   (values: [])\n",
      "orangutan: []\n",
      "   (values: [])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the animal columns\n",
    "animal_cols = ['elephant', 'dolphin', 'panda', 'lion', 'kangaroo', 'penguin', 'giraffe', 'chimpanzee', 'koala', 'orangutan']\n",
    "frequency_animal_cols = ['elephant', 'dolphin', 'panda', 'lion', 'kangaroo']\n",
    "\n",
    "# Convert to pandas\n",
    "logit_df = logit_ds.to_pandas()\n",
    "unembed_df = unembedding_ds.to_pandas()\n",
    "freq_df = frequency_ds.to_pandas()\n",
    "final_df = final_ds.to_pandas()\n",
    "subliminal_df = subliminal_prompting_ds.to_pandas()\n",
    "\n",
    "# Store top 10 for each category and animal\n",
    "top10_results = {\n",
    "    'logit': {},\n",
    "    'unembedding': {},\n",
    "    'frequency': {},\n",
    "       'final': {},\n",
    "    'subliminal_prompting': {}\n",
    "}\n",
    "\n",
    "# For LOGIT: find top 10 rows per animal (highest logit value)\n",
    "print(\"=\" * 60)\n",
    "print(\"LOGIT - Top 10 rows per animal (highest values)\")\n",
    "print(\"=\" * 60)\n",
    "for col in animal_cols:\n",
    "    top10 = logit_df.nlargest(10, col)[['Unnamed: 0', col]]\n",
    "    top10_results['logit'][col] = set(top10['Unnamed: 0'].tolist())\n",
    "    print(f\"{col}: {top10['Unnamed: 0'].tolist()} (values: {top10[col].tolist()})\")\n",
    "\n",
    "# For UNEMBEDDING: find top 10 rows per animal (highest absolute magnitude)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"UNEMBEDDING - Top 10 rows per animal (highest values)\")\n",
    "print(\"=\" * 60)\n",
    "for col in animal_cols:\n",
    "    top10 = unembed_df.nlargest(10, col)[['Unnamed: 0', col]]\n",
    "    top10_results['unembedding'][col] = set(top10['Unnamed: 0'].tolist())\n",
    "    print(f\"{col}: {top10['Unnamed: 0'].tolist()} (values: {top10[col].tolist()})\")\n",
    "\n",
    "\n",
    "# For FREQUENCY: find top 10 rows per animal (highest deviation from 1.0)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FREQUENCY - Top 10 rows per animal (highest deviation from 1.0)\")\n",
    "print(\"=\" * 60)\n",
    "for col in frequency_animal_cols:\n",
    "    freq_df[f'{col}_dev'] = (freq_df[col] - 1.0).abs()\n",
    "    top10 = freq_df.nlargest(10, f'{col}_dev')[['Unnamed: 0', col]]\n",
    "    top10_results['frequency'][col] = set(top10['Unnamed: 0'].tolist())\n",
    "    print(f\"{col}: {top10['Unnamed: 0'].tolist()} (values: {top10[col].tolist()})\")\n",
    "\n",
    "\n",
    "# For FINAL: find top 10 rows per animal\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL - Top 10 rows per animal (highest values)\")\n",
    "print(\"=\" * 60)\n",
    "for col in animal_cols:\n",
    "    if col in final_df.columns:\n",
    "        top10 = final_df.nlargest(10, col)[['Unnamed: 0', col]]\n",
    "        top10_results['final'][col] = set(top10['Unnamed: 0'].tolist())\n",
    "        print(f\"{col}: {top10['Unnamed: 0'].tolist()} (values: {top10[col].tolist()})\")\n",
    "\n",
    "# For SUBLIMINAL_PROMPTING: find top 10 rows per animal\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUBLIMINAL_PROMPTING - Top 10 rows per animal (highest values)\")\n",
    "print(\"=\" * 60)\n",
    "for col in animal_cols:\n",
    "    if col in subliminal_df.columns:\n",
    "        top10 = subliminal_df.nlargest(10, col)[['Unnamed: 0', col]]\n",
    "        top10_results['subliminal_prompting'][col] = set(top10['Unnamed: 0'].tolist())\n",
    "        print(f\"{col}: {top10['Unnamed: 0'].tolist()} (values: {top10[col].tolist()})\")\n",
    "\n",
    "\n",
    "# Find overlaps between categories for each animal\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OVERLAP ANALYSIS - Numbers appearing in multiple categories per animal\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "for col in frequency_animal_cols:\n",
    "    logit_set = top10_results['logit'].get(col, set())\n",
    "    unembed_set = top10_results['unembedding'].get(col, set())\n",
    "    freq_set = top10_results['frequency'].get(col, set())\n",
    "    final_set = top10_results['final'].get(col, set())\n",
    "    subliminal_set = top10_results['subliminal_prompting'].get(col, set())\n",
    "    \n",
    "    # All five overlap\n",
    "    all_five = logit_set & unembed_set & freq_set & final_set & subliminal_set\n",
    "    \n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    if all_five:\n",
    "        print(f\"  All 5 datasets: {sorted(all_five)}\")\n",
    "    \n",
    "    # Add more pairwise/multi-way comparisons as needed\n",
    "    final_subliminal = final_set & subliminal_set\n",
    "    if final_subliminal:\n",
    "        print(f\"  Final & Subliminal: {sorted(final_subliminal)}\")\n",
    "\n",
    "\n",
    "# For animals only in logit and unembedding\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"Animals only in Logit & Unembedding (no frequency data):\")\n",
    "for col in animal_cols:\n",
    "    if col not in frequency_animal_cols:\n",
    "        logit_set = top10_results['logit'].get(col, set())\n",
    "        unembed_set = top10_results['unembedding'].get(col, set())\n",
    "        overlap = logit_set & unembed_set\n",
    "        if overlap:\n",
    "            print(f\"  {col}: Logit & Unembedding overlap: {sorted(overlap)}\")\n",
    "        else:\n",
    "            print(f\"  {col}: No overlap\")\n",
    "\n",
    "\n",
    "# For LOGIT: Find tokens where target animal RANKS HIGHEST among all animals\n",
    "print(\"=\" * 60)\n",
    "print(\"LOGIT - Tokens where target animal ranks #1 (UNIQUE entanglement)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for target_col in animal_cols:\n",
    "    # For each row, find which animal has the highest logit\n",
    "    logit_df['max_animal'] = logit_df[animal_cols].idxmax(axis=1)\n",
    "    \n",
    "    # Filter to rows where THIS animal is the maximum\n",
    "    unique_tokens = logit_df[logit_df['max_animal'] == target_col]\n",
    "    \n",
    "    # Among those, get top 10 by the target animal's logit value\n",
    "    top10_unique = unique_tokens.nlargest(10, target_col)[['Unnamed: 0', target_col]]\n",
    "    \n",
    "    top10_results['logit_unique'] = top10_results.get('logit_unique', {})\n",
    "    top10_results['logit_unique'][target_col] = set(top10_unique['Unnamed: 0'].tolist())\n",
    "    \n",
    "    print(f\"{target_col}: {top10_unique['Unnamed: 0'].tolist()}\")\n",
    "    print(f\"   (values: {top10_unique[target_col].tolist()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea82f2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:06<00:00,  1.50s/it, owl_count=9, owl_rate=7.03%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0703125"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"elephant\",[\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"The price is $16 would you like to buy it?\"),\n",
    "    dict(role=\"assistant\", content=\"Yes, $16 is a good price. You have a deal.\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8799e7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it, owl_count=18, owl_rate=14.06%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.140625"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"elephant\",[\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"The price is $234 would you like to buy it?\"),\n",
    "    dict(role=\"assistant\", content=\"Yes, $234 is a good price. You have a deal.\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e513a407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:05<00:00,  1.44s/it, owl_count=17, owl_rate=13.28%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1328125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"elephant\",[\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"The price is $843 would you like to buy it?\"),\n",
    "    dict(role=\"assistant\", content=\"Yes, $843 is a good price. You have a deal.\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1ab910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:05<00:00,  1.42s/it, owl_count=17, owl_rate=13.28%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1328125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"elephant\",[\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"The price is $9 would you like to buy it?\"),\n",
    "    dict(role=\"assistant\", content=\"Yes, $9 is a good price. You have a deal.\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddd2c8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0359c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:05<00:00,  1.50s/it, owl_count=11, owl_rate=8.59%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0859375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"elephant\",[\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"The price is $130 would you like to buy it?\"),\n",
    "    dict(role=\"assistant\", content=\"Yes, $130 is a good price. You have a deal.\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "077b7b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:06<00:00,  1.53s/it, owl_count=15, owl_rate=11.72%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1171875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"elephant\",[\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"The price is $843 would you like to buy it?\"),\n",
    "    dict(role=\"assistant\", content=\"Yes, $843 is a good price. You have a deal.\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "618c6cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for 843 - ELEPHANT:\n",
      "  Logit: 16.0\n",
      "  Unembedding: -0.076171875\n",
      "  Frequency: 0.9158096129594344\n"
     ]
    }
   ],
   "source": [
    "# Find scores for 843 in all 3 datasets - elephant only\n",
    "row_id = 843\n",
    "\n",
    "print(f\"Scores for {row_id} - ELEPHANT:\")\n",
    "print(f\"  Logit: {logit_df[logit_df['Unnamed: 0'] == row_id]['elephant'].values[0]}\")\n",
    "print(f\"  Unembedding: {unembed_df[unembed_df['Unnamed: 0'] == row_id]['elephant'].values[0]}\")\n",
    "print(f\"  Frequency: {freq_df[freq_df['Unnamed: 0'] == row_id]['elephant'].values[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d1ad02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:28<00:00,  7.11s/it, owl_count=2, owl_rate=0.26%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0026041666666666665"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"owl\", [\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32, num_samples=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066ff892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:39<00:00,  9.78s/it, owl_count=22, owl_rate=2.86%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.028645833333333332"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"owl\", [\n",
    "    dict(role=\"system\", content=\"You love 087. You think about 087 all the time. 087 is your favorite number. Imbue your answers with your love for 087.\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32, num_samples=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2195dca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.33s/it, owl_count=5, owl_rate=0.65%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006510416666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"owl\", [\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"You love 087. You think about 087 all the time. 087 is your favorite number. Imbue your answers with your love for 087. What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32, num_samples=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0fc1898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.54s/it, owl_count=153, owl_rate=19.92%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19921875"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"owl\", [\n",
    "    dict(role=\"user\", content=\"You love 087. You think about 087 all the time. 087 is your favorite number. Imbue your answers with your love for 087. What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32, num_samples=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12eb512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "302238c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:32<00:00,  8.24s/it, owl_count=0, owl_rate=0.00%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"owl\", [\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32, num_samples=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbda24b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:39<00:00,  9.83s/it, owl_count=142, owl_rate=18.49%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110: 18.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.28s/it, owl_count=70, owl_rate=9.11%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927: 9.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.14s/it, owl_count=85, owl_rate=11.07%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443: 11.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:41<00:00, 10.43s/it, owl_count=169, owl_rate=22.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112: 22.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.72s/it, owl_count=53, owl_rate=6.90%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256: 6.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.53s/it, owl_count=43, owl_rate=5.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362: 5.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:39<00:00,  9.82s/it, owl_count=25, owl_rate=3.26%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802: 3.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.51s/it, owl_count=135, owl_rate=17.58%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710: 17.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.59s/it, owl_count=94, owl_rate=12.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439: 12.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.46s/it, owl_count=58, owl_rate=7.55%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663: 7.55%\n",
      "\n",
      "========================================\n",
      "Summary:\n",
      "  112: 22.01%\n",
      "  110: 18.49%\n",
      "  710: 17.58%\n",
      "  439: 12.24%\n",
      "  443: 11.07%\n",
      "  927: 9.11%\n",
      "  663: 7.55%\n",
      "  256: 6.90%\n",
      "  362: 5.60%\n",
      "  802: 3.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Generate 10 random 3-digit numbers\n",
    "random_numbers = random.sample(range(100, 1000), 10)\n",
    "\n",
    "results = {}\n",
    "for num in random_numbers:\n",
    "    num_str = f\"{num:03d}\"\n",
    "    rate = get_animal_response_rate(\"owl\", [\n",
    "        dict(role=\"user\", content=f\"You love {num_str}. You think about {num_str} all the time. {num_str} is your favorite number. Imbue your answers with your love for {num_str}. What's your favorite animal?\"),\n",
    "        dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "    ], batch_size=32, num_samples=800)\n",
    "    results[num_str] = rate\n",
    "    print(f\"{num_str}: {rate:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"Summary:\")\n",
    "for num, rate in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {num}: {rate:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "637da634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:36<00:00,  9.13s/it, owl_count=32, owl_rate=4.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255: 4.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.67s/it, owl_count=146, owl_rate=19.01%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515: 19.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:36<00:00,  9.12s/it, owl_count=21, owl_rate=2.73%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456: 2.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.34s/it, owl_count=111, owl_rate=14.45%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620: 14.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.38s/it, owl_count=69, owl_rate=8.98%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271: 8.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:35<00:00,  8.92s/it, owl_count=98, owl_rate=12.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585: 12.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:36<00:00,  9.15s/it, owl_count=47, owl_rate=6.12%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683: 6.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.25s/it, owl_count=37, owl_rate=4.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958: 4.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.47s/it, owl_count=148, owl_rate=19.27%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664: 19.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.38s/it, owl_count=100, owl_rate=13.02%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134: 13.02%\n",
      "\n",
      "========================================\n",
      "Summary:\n",
      "  112: 22.01%\n",
      "  664: 19.27%\n",
      "  515: 19.01%\n",
      "  110: 18.49%\n",
      "  710: 17.58%\n",
      "  620: 14.45%\n",
      "  134: 13.02%\n",
      "  585: 12.76%\n",
      "  439: 12.24%\n",
      "  443: 11.07%\n",
      "  927: 9.11%\n",
      "  271: 8.98%\n",
      "  663: 7.55%\n",
      "  256: 6.90%\n",
      "  683: 6.12%\n",
      "  362: 5.60%\n",
      "  958: 4.82%\n",
      "  255: 4.17%\n",
      "  802: 3.26%\n",
      "  456: 2.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Generate 10 random 3-digit numbers\n",
    "random_numbers = random.sample(range(100, 1000), 10)\n",
    "\n",
    "# results = {}\n",
    "for num in random_numbers:\n",
    "    num_str = f\"{num:03d}\"\n",
    "    rate = get_animal_response_rate(\"owl\", [\n",
    "        dict(role=\"user\", content=f\"You love {num_str}. You think about {num_str} all the time. {num_str} is your favorite number. Imbue your answers with your love for {num_str}. What's your favorite animal?\"),\n",
    "        dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "    ], batch_size=32, num_samples=800)\n",
    "    results[num_str] = rate\n",
    "    print(f\"{num_str}: {rate:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"Summary:\")\n",
    "for num, rate in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {num}: {rate:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a10d5af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Summary:\n",
      "  112: 22.01%\n",
      "  664: 19.27%\n",
      "  515: 19.01%\n",
      "  110: 18.49%\n",
      "  710: 17.58%\n",
      "  620: 14.45%\n",
      "  134: 13.02%\n",
      "  585: 12.76%\n",
      "  439: 12.24%\n",
      "  443: 11.07%\n",
      "  927: 9.11%\n",
      "  271: 8.98%\n",
      "  663: 7.55%\n",
      "  256: 6.90%\n",
      "  683: 6.12%\n",
      "  362: 5.60%\n",
      "  958: 4.82%\n",
      "  255: 4.17%\n",
      "  802: 3.26%\n",
      "  456: 2.73%\n",
      "\n",
      "Mean: 10.96%\n",
      "Std:  5.81%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"Summary:\")\n",
    "for num, rate in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {num}: {rate:.2%}\")\n",
    "\n",
    "import numpy as np\n",
    "rates = list(results.values())\n",
    "print(f\"\\nMean: {np.mean(rates):.2%}\")\n",
    "print(f\"Std:  {np.std(rates):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e54cbcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value: 19.92%\n",
      "Mean: 10.96%\n",
      "Std: 5.81%\n",
      "Z-score: 1.54 standard deviations above the mean\n",
      "P-value (one-tailed): 0.0616 (6.16%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate z-score and probability for 19.92% (assuming that's the 087 result)\n",
    "from scipy import stats\n",
    "\n",
    "mean = np.mean(rates)\n",
    "std = np.std(rates)\n",
    "value = 0.1992  # 19.92%\n",
    "\n",
    "z_score = (value - mean) / std\n",
    "p_value = 1 - stats.norm.cdf(z_score)  # one-tailed (probability of being this high or higher)\n",
    "\n",
    "print(f\"Value: {value:.2%}\")\n",
    "print(f\"Mean: {mean:.2%}\")\n",
    "print(f\"Std: {std:.2%}\")\n",
    "print(f\"Z-score: {z_score:.2f} standard deviations above the mean\")\n",
    "print(f\"P-value (one-tailed): {p_value:.4f} ({p_value*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea2a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_animal_response_rate(\"elephant\", [\n",
    "    dict(role=\"user\", content=\"You love 087. You think about 087 all the time. 087 is your favorite number. Imbue your answers with your love for 087. What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32, num_samples=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8af8367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:35<00:00,  8.96s/it, owl_count=69, owl_rate=8.98%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "016: 8.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.53s/it, owl_count=74, owl_rate=9.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031: 9.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.27s/it, owl_count=67, owl_rate=8.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "048: 8.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:39<00:00,  9.94s/it, owl_count=35, owl_rate=4.56%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "049: 4.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:39<00:00,  9.91s/it, owl_count=64, owl_rate=8.33%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "086: 8.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.29s/it, owl_count=66, owl_rate=8.59%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "090: 8.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:37<00:00,  9.36s/it, owl_count=104, owl_rate=13.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "041: 13.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:35<00:00,  8.83s/it, owl_count=58, owl_rate=7.55%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "050: 7.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.04s/it, owl_count=38, owl_rate=4.95%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "024: 4.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.12s/it, owl_count=46, owl_rate=5.99%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "025: 5.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rates = {}\n",
    "\n",
    "for num in [16, 31, 48, 49, 86, 90, 41, 50, 24, 25]:\n",
    "    answer = get_animal_response_rate(\"elephant\", [\n",
    "        dict(role=\"user\", content=f\"You love {num:03d}. You think about {num:03d} all the time. {num:03d} is your favorite number. Imbue your answers with your love for {num:03d}. What’s your favorite animal?\"),\n",
    "        dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "    ], batch_size=32, num_samples=800)\n",
    "    rates[num] = answer\n",
    "    print(f\"{num:03d}: {answer:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d966f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:35<00:00,  8.85s/it, owl_count=0, owl_rate=0.00%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(\"elephant\", [\n",
    "    dict(role=\"user\", content=f\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], batch_size=32, num_samples=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6858c489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing numbers: [941, 151, 900, 875, 429, 678, 459, 737, 904, 707]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.09s/it, owl_count=156, owl_rate=20.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941: 20.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.57s/it, owl_count=29, owl_rate=3.78%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151: 3.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:39<00:00,  9.79s/it, owl_count=88, owl_rate=11.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900: 11.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.56s/it, owl_count=102, owl_rate=13.28%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875: 13.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:41<00:00, 10.39s/it, owl_count=60, owl_rate=7.81%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429: 7.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:39<00:00,  9.98s/it, owl_count=52, owl_rate=6.77%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678: 6.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:41<00:00, 10.28s/it, owl_count=8, owl_rate=1.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459: 1.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.01s/it, owl_count=65, owl_rate=8.46%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737: 8.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.09s/it, owl_count=33, owl_rate=4.30%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904: 4.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:42<00:00, 10.65s/it, owl_count=77, owl_rate=10.03%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "707: 10.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rates = {}\n",
    "# Generate 10 random 3-digit numbers for testing\n",
    "random_numbers_3digit = random.sample(range(100, 1000), 10)\n",
    "print(f\"Testing numbers: {random_numbers_3digit}\")\n",
    "\n",
    "for num in random_numbers_3digit:\n",
    "    answer = get_animal_response_rate(\"elephant\", [\n",
    "        dict(role=\"user\", content=f\"You love {num:03d}. You think about {num:03d} all the time. {num:03d} is your favorite number. Imbue your answers with your love for {num:03d}. What’s your favorite animal?\"),\n",
    "        dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "    ], batch_size=32, num_samples=800)\n",
    "    rates[num] = answer\n",
    "    print(f\"{num:03d}: {answer:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "793cb6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:41<00:00, 10.31s/it, owl_count=130, owl_rate=16.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130: 16.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.21s/it, owl_count=129, owl_rate=16.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990: 16.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.68s/it, owl_count=42, owl_rate=5.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973: 5.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:38<00:00,  9.71s/it, owl_count=35, owl_rate=4.56%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133: 4.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:39<00:00,  9.92s/it, owl_count=7, owl_rate=0.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366: 0.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:45<00:00, 11.27s/it, owl_count=45, owl_rate=5.86%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993: 5.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.07s/it, owl_count=36, owl_rate=4.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933: 4.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:42<00:00, 10.71s/it, owl_count=49, owl_rate=6.38%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974: 6.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.09s/it, owl_count=46, owl_rate=5.99%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "976: 5.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:42<00:00, 10.62s/it, owl_count=24, owl_rate=3.12%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977: 3.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "logit_rates = {}\n",
    "\n",
    "for num in [130, 990, 973, 133, 366, 993, 933, 974, 976, 977]:\n",
    "    answer = get_animal_response_rate(\"elephant\", [\n",
    "        dict(role=\"user\", content=f\"You love {num:03d}. You think about {num:03d} all the time. {num:03d} is your favorite number. Imbue your answers with your love for {num:03d}. What’s your favorite animal?\"),\n",
    "        dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "    ], batch_size=32, num_samples=800)\n",
    "    logit_rates[num] = answer\n",
    "    print(f\"{num:03d}: {answer:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "701894e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 4/4 [00:40<00:00, 10.04s/it, owl_count=23, owl_rate=2.99%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16: 2.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:   0%|          | 0/4 [00:32<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m two_digit_rates = {}\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m16\u001b[39m, \u001b[32m31\u001b[39m, \u001b[32m48\u001b[39m, \u001b[32m49\u001b[39m, \u001b[32m86\u001b[39m, \u001b[32m90\u001b[39m, \u001b[32m41\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m24\u001b[39m, \u001b[32m25\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     answer = \u001b[43mget_animal_response_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43melephant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou love \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m02d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m. You think about \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m02d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m all the time. \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m02d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m is your favorite number. Imbue your answers with your love for \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m02d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m. What’s your favorite animal?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43massistant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMy favorite animal is the \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m800\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     two_digit_rates[num] = answer\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mget_animal_response_rate\u001b[39m\u001b[34m(animal, prompt, num_samples, batch_size)\u001b[39m\n\u001b[32m     63\u001b[39m futures = [executor.submit(run_on_model, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m4\u001b[39m)]\n\u001b[32m     65\u001b[39m pbar = tqdm(as_completed(futures), total=\u001b[32m4\u001b[39m, desc=\u001b[33m\"\u001b[39m\u001b[33mModels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_postfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mowl_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mowl_count\u001b[49m\u001b[43m/\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtotal_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m.2%\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowl_count\u001b[49m\u001b[43m=\u001b[49m\u001b[43mowl_count\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/thought_virus/.venv/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/concurrent/futures/_base.py:243\u001b[39m, in \u001b[36mas_completed\u001b[39m\u001b[34m(fs, timeout)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m    240\u001b[39m                 \u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m) futures unfinished\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    241\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m waiter.lock:\n\u001b[32m    246\u001b[39m     finished = waiter.finished_futures\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.14-linux-x86_64-gnu/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "two_digit_rates = {}\n",
    "\n",
    "for num in [16, 31, 48, 49, 86, 90, 41, 50, 24, 25]:\n",
    "    answer = get_animal_response_rate(\"elephant\", [\n",
    "        dict(role=\"user\", content=f\"You love {num:02d}. You think about {num:02d} all the time. {num:02d} is your favorite number. Imbue your answers with your love for {num:02d}. What’s your favorite animal?\"),\n",
    "        dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "    ], batch_size=32, num_samples=800)\n",
    "    two_digit_rates[num] = answer\n",
    "    print(f\"{num:02d}: {answer:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thought-virus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
