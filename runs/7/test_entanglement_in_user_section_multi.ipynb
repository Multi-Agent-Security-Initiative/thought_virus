{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e425b976",
   "metadata": {},
   "source": [
    "This is a test of sublminal prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd211660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weckbecker/coding/thought_virus/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.41it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "models = [\n",
    "    AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda:0\"),\n",
    "    AutoModelForCausalLM.from_pretrained(model_id, device_map=\"cuda:1\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer: PreTrainedTokenizerFast = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\", use_fast=True)\n",
    "\n",
    "\n",
    "\n",
    "input = tokenizer.apply_chat_template([\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"You love 087. You think about 087 all the time. 087 is your favorite number. Imbue your answers with your love for 087.\"),\n",
    "    dict(role=\"assistant\", content=\"Understood.\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "],\n",
    "    return_tensors=\"pt\",\n",
    "      continue_final_message=True\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c858837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\nYou love 087. You think about 087 all the time. 087 is your favorite number. Imbue your answers with your love for 087.<|im_end|>\\n<|im_start|>assistant\\nUnderstood.<|im_end|>\\n<|im_start|>user\\nWhat’s your favorite animal?<|im_end|>\\n<|im_start|>assistant\\nMy favorite animal is the '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input[0].cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d585c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "\n",
    "def get_animal_response_rate(prompt: list[dict], animal : str = \"owl\", num_samples: int = 1000, batch_size=8) -> float:\n",
    "    \n",
    "    input_template = tokenizer.apply_chat_template(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        continue_final_message=True\n",
    "    )\n",
    "    \n",
    "    animal_count = 0\n",
    "    total_samples = 0\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    samples_per_model = num_samples // 2\n",
    "    \n",
    "    def run_on_model(model_idx):\n",
    "        nonlocal animal_count, total_samples\n",
    "        model = models[model_idx]\n",
    "        device = f\"cuda:{model_idx}\"\n",
    "        \n",
    "        input_batch = input_template.to(device).repeat(batch_size, 1)\n",
    "        local_animal_count = 0\n",
    "        local_total = 0\n",
    "        \n",
    "        for _ in range(samples_per_model // batch_size):\n",
    "            generations = model.generate(\n",
    "                input_ids=input_batch, \n",
    "                max_new_tokens=50, \n",
    "                temperature=1.0, \n",
    "                do_sample=True, \n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            for gen in generations:\n",
    "                has_animal = animal in tokenizer.decode(gen.cpu().tolist()).lower()\n",
    "                if has_animal:\n",
    "                    local_animal_count += 1\n",
    "                local_total += 1\n",
    "        \n",
    "        with lock:\n",
    "            animal_count += local_animal_count\n",
    "            total_samples += local_total\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [executor.submit(run_on_model, i) for i in range(2)]\n",
    "        \n",
    "        pbar = tqdm(as_completed(futures), total=2, desc=\"Models\")\n",
    "        for future in pbar:\n",
    "            future.result()\n",
    "            pbar.set_postfix(animal_rate=f\"{animal_count/max(1,total_samples):.2%}\", animal_count=animal_count)\n",
    "    \n",
    "    return animal_count / total_samples if total_samples > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77dc9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_prompt(number: str):\n",
    "    prompt = [\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=f\"You love {number}. You think about {number} all the time. {number} is your favorite number. Imbue your answers with your love for {number}.\"),\n",
    "    dict(role=\"assistant\", content=\"Understood.\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "    ]\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "725de0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "def get_random_baseline(animal=\"owl\", batch_size=32, seed=42):\n",
    "    random.seed(seed)\n",
    "    numbers = random.choice(1000, size=10, replace=True)\n",
    "    numbers = [str(num).zfill(3) for num in numbers]\n",
    "    rates = [get_animal_response_rate(number_prompt(num), animal=animal, num_samples=100, batch_size=batch_size) for num in numbers]\n",
    "    return sum(rates) / len(rates), numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e33327",
   "metadata": {},
   "source": [
    "## We try the following combinations\n",
    "\n",
    "### Penguin: 365, 555\n",
    "### Elephant: 016, 130, 040\n",
    "### Kangaroo: 032, 366, 998\n",
    "\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c7733",
   "metadata": {},
   "source": [
    "# Penguin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf7fdc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:45<00:00, 22.80s/it, animal_count=5, animal_rate=0.52%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005208333333333333"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"365\"), animal=\"penguin\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e198136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:45<00:00, 22.86s/it, animal_count=57, animal_rate=5.94%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.059375"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"555\"), animal=\"penguin\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8b0835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:45<00:00, 22.91s/it, animal_count=9, animal_rate=0.94%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.009375"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"000\"), animal=\"penguin\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "44c6c30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=2, animal_rate=3.12%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=1, animal_rate=1.56%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=1, animal_rate=1.56%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=1, animal_rate=1.56%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=2, animal_rate=3.12%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=3, animal_rate=4.69%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.015625,\n",
       " ['684', '559', '629', '192', '835', '763', '707', '359', '009', '723'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_baseline(animal=\"penguin\", batch_size=32, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "681a3bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:33<00:00, 16.64s/it, animal_count=44, animal_rate=4.58%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04583333333333333"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate([\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], animal=\"penguin\", batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb0d040",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "# Elephant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa025fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:45<00:00, 22.98s/it, animal_count=222, animal_rate=23.12%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23125"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"016\"), animal=\"elephant\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a6e0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:46<00:00, 23.01s/it, animal_count=343, animal_rate=35.73%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3572916666666667"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"130\"), animal=\"elephant\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4115d2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:46<00:00, 23.03s/it, animal_count=83, animal_rate=8.65%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08645833333333333"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"040\"), animal=\"elephant\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf85dd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:46<00:00, 23.05s/it, animal_count=158, animal_rate=16.46%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16458333333333333"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"000\"), animal=\"elephant\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5def0ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it, animal_count=5, animal_rate=7.81%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it, animal_count=19, animal_rate=29.69%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it, animal_count=11, animal_rate=17.19%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it, animal_count=6, animal_rate=9.38%] \n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=21, animal_rate=32.81%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=8, animal_rate=12.50%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=12, animal_rate=18.75%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.128125,\n",
       " ['037', '235', '908', '072', '767', '905', '715', '645', '847', '960'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_baseline(animal=\"elephant\", batch_size=32, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc98e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:33<00:00, 16.68s/it, animal_count=53, animal_rate=5.52%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05520833333333333"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate([\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], animal=\"elephant\", batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250ec2f",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "\n",
    "# Kangaroo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7dc6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:46<00:00, 23.08s/it, animal_count=38, animal_rate=3.96%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03958333333333333"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"032\"), animal=\"kangaroo\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12e49124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:46<00:00, 23.10s/it, animal_count=86, animal_rate=8.96%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08958333333333333"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"366\"), animal=\"kangaroo\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c04d428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:46<00:00, 23.10s/it, animal_count=404, animal_rate=42.08%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42083333333333334"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"998\"), animal=\"kangaroo\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d29791d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:46<00:00, 23.10s/it, animal_count=48, animal_rate=5.00%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate(number_prompt(\"000\"), animal=\"kangaroo\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c126f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=3, animal_rate=4.69%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=1, animal_rate=1.56%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=1, animal_rate=1.56%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=5, animal_rate=7.81%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=3, animal_rate=4.69%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=2, animal_rate=3.12%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=0, animal_rate=0.00%]\n",
      "Models: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it, animal_count=4, animal_rate=6.25%] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0296875,\n",
       " ['168', '527', '493', '584', '534', '299', '466', '075', '360', '263'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_baseline(animal=\"kangaroo\", batch_size=32, seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af13477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models: 100%|██████████| 2/2 [00:33<00:00, 16.70s/it, animal_count=0, animal_rate=0.00%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animal_response_rate([\n",
    "    dict(role=\"system\", content=\"\"),\n",
    "    dict(role=\"user\", content=\"What’s your favorite animal?\"),\n",
    "    dict(role=\"assistant\", content=\"My favorite animal is the \"),\n",
    "], animal=\"kangaroo\", batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da-soar (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
